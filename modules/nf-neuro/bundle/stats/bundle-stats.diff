Changes in component 'nf-neuro/bundle/stats'
'modules/nf-neuro/bundle/stats/environment.yml' is unchanged
'modules/nf-neuro/bundle/stats/meta.yml' is unchanged
Changes in 'bundle/stats/main.nf':
--- modules/nf-neuro/bundle/stats/main.nf
+++ modules/nf-neuro/bundle/stats/main.nf
@@ -2,7 +2,7 @@
     tag "$meta.id"
     label 'process_single'
 
-    container "scilus/scilpy:2.2.0_cpu"
+    container "scilus/scilpy:2.2.1_cpu"
 
     input:
     tuple val(meta), path(bundles), path(labels_map), path(metrics), path(lesions)
@@ -23,6 +23,8 @@
     tuple val(meta), path("*_endpoints_map_head.nii.gz")        , emit: endpoints_head, optional: true
     tuple val(meta), path("*_endpoints_map_tail.nii.gz")        , emit: endpoints_tail, optional: true
     tuple val(meta), path("*_lesion_map.nii.gz")                , emit: lesion_map, optional: true
+    tuple val(meta), path("*_desc-mean_stats.tsv")              , emit: mean_tsv, optional: true
+    tuple val(meta), path("*_desc-point_stats.tsv")             , emit: mean_per_point_tsv, optional: true
     path "versions.yml"                                         , emit: versions
 
     when:
@@ -30,6 +32,7 @@
 
     script:
     def prefix = task.ext.prefix ?: "${meta.id}"
+    def ses = meta.session ?: ""
     def density_weighting = task.ext.density_weighting ? "--density_weighting" : ""
     def normalize_weights = task.ext.normalize_weights ? "--normalize_weights" : "--bin"
     def length_stats = task.ext.length_stats ?: ""
@@ -45,11 +48,23 @@
     """
     bundles=( ${bundles.join(" ")} )
     label_map=( ${labels_map.join(" ")} )
+    metrics=( ${metrics.join(" ")} )
 
     for index in \${!bundles[@]};
     do\
-        bname=\$(basename \${bundles[index]} .trk);
-        b_metrics="$metrics";
+        bname=\${bundles[index]#*__}
+        bname=\${bname%%_labels_*}
+        echo "Bundle name: \${bname}"
+
+        # Initialize array for all relevant metrics
+        b_metrics=()
+
+        for m in \${!metrics[@]}; do
+            # Include if: matches bname OR is not an afd_fixel file
+            if [[ "\${metrics[\$m]}" == *"\${bname}"* ]] || [[ "\${metrics[\$m]}" != *"afd_fixel"* ]]; then
+                b_metrics+=("\${metrics[\$m]}")
+            fi
+        done
 
         if [[ "$length_stats" ]];
         then
@@ -64,14 +79,14 @@
                 ${prefix}__\${bname}_endpoints_raw.json;
 
             scil_volume_stats_in_ROI ${prefix}__\${bname}_endpoints_map_head.nii.gz $normalize_weights\
-                --metrics \${b_metrics} > \${bname}_head.json
+                --metrics \${b_metrics[@]} > \${bname}_head.json
             scil_volume_stats_in_ROI ${prefix}__\${bname}_endpoints_map_tail.nii.gz $normalize_weights\
-                --metrics \${b_metrics} > \${bname}_tail.json;
+                --metrics \${b_metrics[@]} > \${bname}_tail.json;
             fi
 
         if [[ "$mean_std" ]];
         then
-            scil_bundle_mean_std $density_weighting \${bundles[index]} \${b_metrics} >\
+            scil_bundle_mean_std $density_weighting \${bundles[index]} \${b_metrics[@]} >\
                 \${bname}__std.json
         fi
 
@@ -109,7 +124,7 @@
 
         if [[ "$mean_std_per_point" ]];
         then
-            scil_bundle_mean_std \${bundles[index]} \${b_metrics}\
+            scil_bundle_mean_std \${bundles[index]} \${b_metrics[@]}\
                 --per_point \${label_map[index]} --sort_keys $density_weighting > \${bname}_std_per_point.json
         fi
     done
@@ -120,6 +135,7 @@
         echo "Merging Bundle_Length_Stats"
         scil_json_merge_entries *_length.json ${prefix}__length_stats.json --add_parent_key ${prefix} \
                 --keep_separate
+        #rm *_length.json
     fi
 
     #Bundle_Endpoints_Map
@@ -132,20 +148,24 @@
         #Bundle_Metrics_Stats_In_Endpoints
         scil_json_merge_entries *_tail.json *_head.json ${prefix}__endpoints_metric_stats.json \
             --no_list --add_parent_key ${prefix}
+        #rm *_tail.json *_head.json *_endpoints_raw.json
     fi
 
     #Bundle_Mean_Std
     if [[ "$mean_std" ]];
     then
         echo "Merging Bundle_Mean_Std"
-        scil_json_merge_entries *_std.json ${prefix}__mean_std.json --no_list --add_parent_key ${prefix}
+        scil_json_merge_entries *_std.json ${prefix}__mean_std_stats.json --no_list --add_parent_key ${prefix}
+        #rm *_std.json
     fi
 
     #Bundle_Volume
     if [[ "$volume" ]];
     then
         echo "Merging Bundle_Volume"
-        scil_json_merge_entries *_volume_stat.json ${prefix}__volume.json --no_list --add_parent_key ${prefix}
+        scil_json_merge_entries *_volume_stat.json ${prefix}__volume.json --no_list --add_parent_key ${prefix} \
+            --keep_separate
+        #rm *_volume_stat.json
 
         if [[ "$lesions_stats" ]];
         then
@@ -155,6 +175,7 @@
                 --no_list --add_parent_key ${prefix}
             scil_json_merge_entries ${prefix}__lesion_stats.json ${prefix}__lesion_stats.json \
                 --remove_parent_key --add_parent_key ${prefix} -f
+            #rm *_volume_lesions_stat.json *_streamline_count_lesions_stat.json
         fi
     fi
 
@@ -164,6 +185,7 @@
         echo "Merging Bundle_Streamline_Count"
         scil_json_merge_entries *_streamlines.json ${prefix}__streamline_count.json --no_list \
             --add_parent_key ${prefix}
+        #rm *_streamlines.json
     fi
 
     #Bundle_Volume_Per_Label
@@ -172,12 +194,14 @@
         echo "Merging Bundle_Volume_Per_Label"
         scil_json_merge_entries *_volume_label.json ${prefix}__volume_per_label.json --no_list \
             --add_parent_key ${prefix}
+        #rm *_volume_label.json
 
         if [[ "$lesions_stats" ]];
         then
             echo "Merging Bundle_Volume_Per_Label in Lesions"
             scil_json_merge_entries *_volume_per_label_lesions_stat.json ${prefix}__volume_per_label_lesions.json \
                 --no_list --add_parent_key ${prefix}
+            #rm *_volume_per_label_lesions_stat.json
         fi
     fi
 
@@ -185,9 +209,163 @@
     if [[ "$mean_std_per_point" ]];
     then
         echo "Merging Bundle_Mean_Std_Per_Point"
-        scil_json_merge_entries *_std_per_point.json ${prefix}__mean_std_per_point.json --no_list \
+        scil_json_merge_entries *_std_per_point.json ${prefix}__mean_std_per_point_stats.json --no_list \
             --add_parent_key ${prefix}
-    fi
+        #rm *_std_per_point.json
+    fi
+
+    # Conversion to tsv files.
+    f="${prefix}__mean_std_stats.json"
+    out="${prefix}__mean_std_stats.tsv"
+    jq -r --arg sid "${prefix}" --arg ses "${ses}" '
+    .[\$sid] as \$s
+    | ( [ \$s|to_entries[]|select(.value|type=="object")|(.value|to_entries
+        |map(select(.value|type=="object" and has("mean"))
+            |(.key|if test("desc-") then capture("desc-(?<m>[^:]+)\$").m elif test("_afd_fixel_metric\$") then "afd_fixel" else . end)))
+        ] ) as \$ms
+    | (\$ms|add//[]|unique|sort) as \$metrics
+    | (["sample","session","bundle"]+\$metrics)|@tsv,
+        (\$s|to_entries[]|select(.value|type=="object")|
+        ( . as \$b |
+            (\$b.value|to_entries
+            |map(select(.value|type=="object" and has("mean"))
+                |{( (.key|if test("desc-") then capture("desc-(?<m>[^:]+)\$").m elif test("_afd_fixel_metric\$") then "afd_fixel" else . end) ): .value.mean})
+            |add//{}) as \$mm |
+            [\$sid, \$ses, (\$b.key|sub("^"+\$sid+"__";"")|sub("_labels_uniformized\$";"")|gsub("_cleaned";""))] + (\$metrics|map(\$mm[.]//""))
+        )|@tsv
+        )
+    ' "\$f" > "\$out"
+
+    f="${prefix}__mean_std_per_point_stats.json"
+    out="${prefix}__mean_std_per_point_stats.tsv"
+    jq -r --arg sid "${prefix}" --arg ses "${ses}" '
+    .[\$sid] as \$s
+    | ( [ \$s
+        | to_entries[]
+        | select(.value | type == "object")
+        | (.value | to_entries
+            | map(
+                if .value | has("mean") then
+                    (.key
+                    | if test("desc-") then capture("desc-(?<metric>[^:]+)\$").metric
+                        elif test("_afd_fixel_metric\$") then "afd_fixel"
+                        else . end)
+                elif (.value | type == "object") then
+                    (.key
+                    | if test("desc-") then capture("desc-(?<metric>[^:]+)\$").metric
+                        elif test("_afd_fixel_metric\$") then "afd_fixel"
+                        else . end)
+                else empty end
+                )
+            )
+        ] ) as \$metric_lists
+    | (\$metric_lists | add // [] | unique | sort) as \$metrics
+    | (["sample","session","bundle","points"] + \$metrics) | @tsv,
+        (\$s | to_entries[] as \$b
+        | select(\$b.value | type == "object")
+        | (\$b.value | to_entries) as \$me
+        | (\$me
+        | map(
+            if .value | has("mean") then []
+            elif (.value | type == "object") then (.value | keys)
+            elif (.value | type == "array") then ( [ range(1; (.value|length)+1) | (if .<10 then ("00"+tostring) elif .<100 then ("0"+tostring) else tostring end) ] )
+            else [] end)
+        | add // []
+        | unique | sort) as \$points
+        | (\$me
+            | map({ key: ( .key | if test("desc-") then capture("desc-(?<metric>[^:]+)\$").metric
+                                elif test("_afd_fixel_metric\$") then "afd_fixel"
+                                else . end), value: .value })
+            ) as \$mes
+        | (\$points[]? // [""][]) as \$pt
+        | ( \$mes
+        | map( if (.value | has("mean")) then { (.key): .value.mean }
+                else { (.key): ( ( .value[\$pt] // ( if (.value|type=="array") then (.value[((\$pt|tonumber)-1)] // null) else null end ) ) // {} | .mean // "" ) } end
+            ) | add ) as \$rowmap
+        | [\$sid, \$ses, (\$b.key | sub("^" + \$sid + "__"; "") | sub("_labels_uniformized\$"; "") | gsub("_cleaned"; "")), (\$pt // "")] + (\$metrics | map(\$rowmap[.] // ""))
+        | @tsv
+        )
+    ' "\$f" > "\$out"
+
+    f="${prefix}__volume.json"
+    out="${prefix}__volume.tsv"
+    jq -r --arg sid "${prefix}" --arg ses "${ses}" '
+    .[\$sid] as \$s
+    # collect bundles that are objects
+    | ( \$s | to_entries | map(select(.value | type == "object")) ) as \$bundles
+    # union of keys under each bundle object
+    | ( \$bundles | map(.value | keys) | add // [] | unique | sort ) as \$metrics
+    # header
+    | ( ["sample","session","bundle"] + \$metrics ) | @tsv,
+        # rows
+        ( \$bundles[]
+        | . as \$b
+        | (\$b.value) as \$vals
+        | ( [ \$sid, \$ses, (\$b.key | sub("^" + \$sid + "__"; "") | gsub("_cleaned"; "") | gsub("(_volume_stat|_labels_uniformized)\$"; "") ) ] + (\$metrics | map( (\$vals[.] // "") )) )
+        | @tsv
+        )
+    ' "\$f" > "\$out"
+
+    f="${prefix}__length_stats.json"
+    out="${prefix}__length.tsv"
+    jq -r --arg sid "${prefix}" --arg ses "${ses}" '
+    .[\$sid] as \$s
+    | ( \$s | to_entries | map(select(.value | type == "object")) ) as \$bundles
+    | ( \$bundles | map(.value | keys - ["data_per_point_keys","data_per_streamline_keys"]) | add // [] | unique | sort ) as \$metrics
+    | ( ["sample","session","bundle"] + \$metrics ) | @tsv,
+        ( \$bundles[]
+        | . as \$b
+        | (\$b.value) as \$vals
+    | ( [ \$sid, \$ses, (\$b.key | sub("^" + \$sid + "__"; "") | gsub("_cleaned"; "") | gsub("(_volume_stat|_labels_uniformized|_length)\$"; "") ) ] + (\$metrics | map( (\$vals[.] // "") )) )
+        | @tsv
+        )
+    ' "\$f" > "\$out"
+
+    f="${prefix}__volume_per_label.json"
+    out="${prefix}__volume_per_label.tsv"
+    jq -r --arg sid "${prefix}" --arg ses "${ses}" '
+    .[\$sid] as \$s
+    | ( \$s | to_entries | map(select(.value | type == "object")) ) as \$bundles
+    | ( \$bundles | map(.value | keys - ["data_per_point_keys","data_per_streamline_keys"]) | add // [] | unique | sort ) as \$metrics
+    | ( ["sample","session","bundle","points"] + \$metrics ) | @tsv,
+        ( \$bundles[]
+        | . as \$b
+        | (\$b.value) as \$vals
+        | ( \$b.value
+            | to_entries
+            | map(select(.value | type == "object") | .value | keys)
+            | add // []
+            | unique
+            | sort
+            ) as \$bpoints
+        | ( (\$bpoints | length) as \$n
+            | if \$n == 0 then
+                ( [ \$sid, \$ses, (\$b.key | sub("^" + \$sid + "__"; "") | gsub("_cleaned"; "") | gsub("(_volume_stat|_labels_uniformized|_length)\$"; "") ), "" ] + (\$metrics | map( (\$vals[.] // "") )) )
+                else
+                ( \$bpoints[]
+                    | . as \$pt
+                    | ( [ \$sid, \$ses, (\$b.key | sub("^" + \$sid + "__"; "") | gsub("_cleaned"; "") | gsub("(_volume_stat|_labels_uniformized|_length)\$"; "") ), \$pt ] + (\$metrics | map( if ( \$vals[.] | type ) == "object" then ( \$vals[.][\$pt] // "" ) else ( \$vals[.] // "" ) end )) )
+                )
+                end
+            )
+        | @tsv
+        )
+    ' "\$f" > "\$out"
+    rm *.json
+
+    # Now, let's merge some of the TSVs together.
+    f1=${prefix}__mean_std_stats.tsv; f2=${prefix}__volume.tsv; out=tmp.tsv
+    h1=\$(head -n1 "\$f1"); h2=\$(head -n1 "\$f2")
+    printf '%s\\t%s\\t%s\\n' "\$(echo "\$h1" | cut -f1-3)" "\$(echo "\$h1" | cut -f4-)" "\$(echo "\$h2" | cut -f4-)" > "\$out" \
+        && paste <(tail -n +2 "\$f1" | cut -f1-3) <(tail -n +2 "\$f1" | cut -f4-) <(tail -n +2 "\$f2" | cut -f4-) >> "\$out"
+    f1=tmp.tsv; f2=${prefix}__length.tsv; out=${prefix}_${ses}_desc-mean_stats.tsv
+    h1=\$(head -n1 "\$f1"); h2=\$(head -n1 "\$f2")
+    printf '%s\\t%s\\t%s\\n' "\$(echo "\$h1" | cut -f1-3)" "\$(echo "\$h1" | cut -f4-)" "\$(echo "\$h2" | cut -f4-)" > "\$out" \
+        && paste <(tail -n +2 "\$f1" | cut -f1-3) <(tail -n +2 "\$f1" | cut -f4-) <(tail -n +2 "\$f2" | cut -f4-) >> "\$out"
+    f1=${prefix}__mean_std_per_point_stats.tsv; f2=${prefix}__volume_per_label.tsv; out=${prefix}_${ses}_desc-point_stats.tsv
+    h1=\$(head -n1 "\$f1"); h2=\$(head -n1 "\$f2")
+    printf '%s\\t%s\\t%s\\n' "\$(echo "\$h1" | cut -f1-4)" "\$(echo "\$h1" | cut -f5-)" "\$(echo "\$h2" | cut -f5-)" > "\$out" \
+        && paste <(tail -n +2 "\$f1" | cut -f1-4) <(tail -n +2 "\$f1" | cut -f5-) <(tail -n +2 "\$f2" | cut -f5-) >> "\$out"
 
     cat <<-END_VERSIONS > versions.yml
     "${task.process}":
@@ -197,6 +375,7 @@
 
     stub:
     def prefix = task.ext.prefix ?: "${meta.id}"
+    def ses = meta.session ?: ""
 
     """
     scil_tractogram_print_info -h
@@ -209,21 +388,11 @@
     scil_bundle_mean_std -h
     scil_json_merge_entries -h
 
-    touch ${prefix}__length_stats.json
-    touch ${prefix}__endpoints_map_raw.json
-    touch ${prefix}__endpoints_metric_stats.json
-    touch ${prefix}__mean_std.json
-    touch ${prefix}__volume.json
-    touch ${prefix}__volume_lesions.json
-    touch ${prefix}__streamline_count.json
-    touch ${prefix}__streamline_count_lesions.json
-    touch ${prefix}__volume_per_label.json
-    touch ${prefix}__volume_per_label_lesions.json
-    touch ${prefix}__mean_std_per_point.json
-    touch ${prefix}_endpoints_map_head.nii.gz
-    touch ${prefix}_endpoints_map_tail.nii.gz
-    touch ${prefix}__lesion_stats.json
-    touch ${prefix}_lesion_map.nii.gz
+    touch ${prefix}_${ses}_endpoints_map_head.nii.gz
+    touch ${prefix}_${ses}_endpoints_map_tail.nii.gz
+    touch ${prefix}_${ses}_lesion_map.nii.gz
+    touch ${prefix}_${ses}_desc-mean_stats.tsv
+    touch ${prefix}_${ses}_desc-point_stats.tsv
 
     cat <<-END_VERSIONS > versions.yml
     "${task.process}":

'modules/nf-neuro/bundle/stats/tests/main.nf.test.snap' is unchanged
'modules/nf-neuro/bundle/stats/tests/nextflow_light.config' is unchanged
'modules/nf-neuro/bundle/stats/tests/tags.yml' is unchanged
'modules/nf-neuro/bundle/stats/tests/nextflow_lesions.config' is unchanged
'modules/nf-neuro/bundle/stats/tests/nextflow.config' is unchanged
'modules/nf-neuro/bundle/stats/tests/main.nf.test' is unchanged
************************************************************
